{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and inital setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# Import Helper Functions\n",
    "# img_load_and_transform\n",
    "# im_string\n",
    "\n",
    "SEED = 42\n",
    "MAX_SAMPLES = 1500\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "# File path variables\n",
    "# please make sure to use the correct path to the meta data file\n",
    "\n",
    "FILEPATH_JPGS = './../data/jpgs/'\n",
    "FILEPATH_METADATA=\"./../data/processed/Metadata_processed.csv\"\n",
    "FILEPATH_OUTPUT = './../data/jpgs/' \n",
    "\n",
    "TARGET_LABEL=\"dx_binary\" # Needed for test train split\n",
    "BALANCE_LABEL=\"dx\"      # Needed for balancing the dataset\n",
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting all previously augmented images in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted augmented images with 'aug_' prefix in ./../data/jpgs/\n"
     ]
    }
   ],
   "source": [
    "# Define the bash script as a string\n",
    "bash_script = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "output_folder=\"./../data/jpgs/\" \n",
    "\n",
    "# Delete images with the \"aug_\" prefix\n",
    "find \"$output_folder\" -type f -name \"aug_*\" -delete\n",
    "\n",
    "echo \"Deleted augmented images with 'aug_' prefix in $output_folder\"\n",
    "\"\"\"\n",
    "\n",
    "# Save the bash script to a file\n",
    "with open('delete_augmented_images.sh', 'w') as script_file:\n",
    "    script_file.write(bash_script)\n",
    "\n",
    "# Make the script executable\n",
    "!chmod +x delete_augmented_images.sh\n",
    "\n",
    "# Execute the script\n",
    "!./delete_augmented_images.sh\n",
    "\n",
    "# Delete the script\n",
    "!rm delete_augmented_images.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dx_binary</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0027419.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0025030.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0026769.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0025661.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0031633.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id          image_id   dx dx_type   age   sex localization   \n",
       "0  HAM_0000118  ISIC_0027419.jpg  bkl   histo  80.0  male        scalp  \\\n",
       "1  HAM_0000118  ISIC_0025030.jpg  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769.jpg  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661.jpg  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633.jpg  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset        dx_binary                       image_path  \n",
       "0  vidir_modern  not_skin_cancer  ./../data/jpgs/ISIC_0027419.jpg  \n",
       "1  vidir_modern  not_skin_cancer  ./../data/jpgs/ISIC_0025030.jpg  \n",
       "2  vidir_modern  not_skin_cancer  ./../data/jpgs/ISIC_0026769.jpg  \n",
       "3  vidir_modern  not_skin_cancer  ./../data/jpgs/ISIC_0025661.jpg  \n",
       "4  vidir_modern  not_skin_cancer  ./../data/jpgs/ISIC_0031633.jpg  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the metadata file\n",
    "metadata = pd.read_csv(FILEPATH_METADATA)\n",
    "\n",
    "# Concatenate the base directory with the image filename to add the full path\n",
    "metadata['image_path'] = FILEPATH_JPGS + metadata['image_id']\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data in train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6009, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2003, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2003, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Splitting the data into train, validation and test using train_test_split\n",
    "\n",
    "# Split the data into two subsets: train and temp (60% train, 40% temp)\n",
    "train_df, temp_df = train_test_split(metadata, test_size=0.4, stratify=metadata[TARGET_LABEL], random_state=SEED)\n",
    "\n",
    "# Split the temp data into validation and test sets (50% each)\n",
    "validation_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[TARGET_LABEL], random_state=SEED)\n",
    "\n",
    "# resetting the index\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validation_df = validation_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "display(\n",
    "    train_df.shape,\n",
    "    validation_df.shape,\n",
    "    test_df.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tackling Class imbalances in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the image data generator for augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_augment = ImageDataGenerator(\n",
    "    rotation_range=40,   # Randomly rotate images by up to 40 degrees\n",
    "    width_shift_range=0.2,  # Randomly shift the width by up to 20%\n",
    "    height_shift_range=0.2, # Randomly shift the height by up to 20%\n",
    "    shear_range=0.2,     # Apply shear transformations\n",
    "    zoom_range=0.2,      # Apply zoom transformations\n",
    "    horizontal_flip=True, # Randomly flip images horizontally\n",
    "    fill_mode='nearest'  # Fill in missing pixels with the nearest value\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class bkl has 660 samples\n",
      "Class mel has 654 samples\n",
      "Class nv has 4018 samples\n",
      "Class akiec has 203 samples\n",
      "Class bcc has 315 samples\n",
      "Class df has 77 samples\n",
      "Class vasc has 82 samples\n"
     ]
    }
   ],
   "source": [
    "# Create separate DataFrames for every class  in the given BALANCE_LABEL column\n",
    "\n",
    "class_dataframes = {}\n",
    "for class_label in train_df[BALANCE_LABEL].unique():\n",
    "    class_dataframes[class_label] = train_df[train_df[BALANCE_LABEL] == class_label]\n",
    "    print(f\"Class {class_label} has {class_dataframes[class_label].shape[0]} samples\")\n",
    "    #display(class_dataframes[class_label].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking class bkl...\n",
      "> Result: Class bkl needs 840 more images\n",
      "Progress: 840/840\n",
      "Checking class mel...\n",
      "> Result: Class mel needs 846 more images\n",
      "Progress: 846/846\n",
      "Checking class nv...\n",
      "> Result: Class nv was reduced to 1500 samples\n",
      "\n",
      "Checking class akiec...\n",
      "> Result: Class akiec needs 1297 more images\n",
      "Progress: 1297/1297\n",
      "Checking class bcc...\n",
      "> Result: Class bcc needs 1185 more images\n",
      "Progress: 1185/1185\n",
      "Checking class df...\n",
      "> Result: Class df needs 1423 more images\n",
      "Progress: 1423/1423\n",
      "Checking class vasc...\n",
      "> Result: Class vasc needs 1418 more images\n",
      "Progress: 1418/1418"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10506, 10)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a dictionary to keep track of the number of augmented images per class\n",
    "class_augmentation_counts = {class_label: 0 for class_label in class_dataframes.keys()}\n",
    "\n",
    "# Create a list to store DataFrames for each class\n",
    "augmented_dataframes = []\n",
    "\n",
    "# Apply data augmentation for classes with few examples, trim classes with too many examples\n",
    "for class_label, class_df in class_dataframes.items():\n",
    "    \n",
    "    # Describing the overall progress\n",
    "    print(f\"\\nChecking class {class_label}...\")\n",
    "\n",
    "    # Calculate the number of images needed to reach MAX_SAMPLES for this class\n",
    "    images_needed = MAX_SAMPLES - class_df.shape[0]\n",
    "    \n",
    "    # If images_needed is negative, randomly select MAX_SAMPLES from the class_df\n",
    "    if images_needed < 0:\n",
    "        print(f\"> Result: Class {class_label} was reduced to {MAX_SAMPLES} samples\")\n",
    "        reduced_df = class_df.sample(n=MAX_SAMPLES, random_state=SEED)\n",
    "        augmented_dataframes.append(reduced_df)\n",
    "        continue\n",
    "    # If images_needed is zero, skip this class\n",
    "    elif images_needed == 0:\n",
    "        print(f\"> Result: Class {class_label} already has exactly {MAX_SAMPLES} samples\")\n",
    "        augmented_dataframes.append(class_df)\n",
    "        continue\n",
    "\n",
    "    # Generate augmented data - this part only runs if images_needed is positive\n",
    "    print(f\"> Result: Class {class_label} needs {images_needed} more images\")\n",
    "    augmented_dataframes.append(class_df)\n",
    "\n",
    "    while class_augmentation_counts[class_label] <= images_needed:\n",
    "\n",
    "        # Describing the subprocess progress for each class\n",
    "        sys.stdout.write(f\"\\rProgress: {class_augmentation_counts[class_label]}/{images_needed}\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        # Randomly select an image from the class_df\n",
    "        i = random.randint(0, class_df.shape[0] - 1)\n",
    "        image_path = class_df.iloc[i]['image_path']\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        img = load_and_preprocess_image(image_path)\n",
    "\n",
    "        # Save the augmented image to the output folder\n",
    "        augmented_image_path = os.path.join(FILEPATH_OUTPUT, augmented_image_id)\n",
    "        plt.imsave(augmented_image_path, augmented_img)\n",
    "\n",
    "        # Apply data augmentation via generator\n",
    "        augmented_img = datagen_augment.random_transform(img)\n",
    "\n",
    "        # Create a new image ID with prefix\n",
    "        augmented_image_id = f'aug_{generate_random_string()}' + os.path.basename(image_path)\n",
    "\n",
    "        # Create a new image path with the augmented image ID as string\n",
    "        augmented_image_path = FILEPATH_JPGS + augmented_image_id\n",
    "        \n",
    "        # Create a new DataFrame for the augmented data for this instance only\n",
    "        augmented_instance_df = class_df.iloc[i:i+1].copy()\n",
    "        \n",
    "        # Reset the index of the new DataFrame\n",
    "        augmented_instance_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Update the \"image_id\" column with the augmented image ID\n",
    "        augmented_instance_df.at[0, 'image_id'] = augmented_image_id\n",
    "        \n",
    "        # Update the \"image_path\" column with the augmented image path\n",
    "        augmented_instance_df.at[0, 'image_path'] = augmented_image_path\n",
    "        \n",
    "        # Append the augmented DataFrame for this instance to the list\n",
    "        augmented_dataframes.append(augmented_instance_df)\n",
    "\n",
    "        # Update the counter for the class\n",
    "        class_augmentation_counts[class_label] += 1\n",
    "\n",
    "# Combine all augmented DataFrames into a single DataFrame\n",
    "balanced_train_df = pd.concat(augmented_dataframes, ignore_index=True)\n",
    "\n",
    "balanced_train_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function: Checking the image file folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in folder: 17031\n",
      "Files starting with 'aug_': 7015\n"
     ]
    }
   ],
   "source": [
    "# Checking what's going on in the fleder\n",
    "\n",
    "def count_files_in_folder(folder_path):\n",
    "    # Initialize counters\n",
    "    total_files = 0\n",
    "    aug_files = 0\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if os.path.exists(folder_path):\n",
    "        # List all files in the folder\n",
    "        files = os.listdir(folder_path)\n",
    "        \n",
    "        # Count all files and files starting with \"aug_\"\n",
    "        for file in files:\n",
    "            total_files += 1\n",
    "            if file.startswith(\"aug_\"):\n",
    "                aug_files += 1\n",
    "\n",
    "        # Display the counts\n",
    "        print(f\"Total files in folder: {total_files}\")\n",
    "        print(f\"Files starting with 'aug_': {aug_files}\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' does not exist.\")\n",
    "\n",
    "# Example usage:\n",
    "folder_path = \"./../data/jpgs/\"  # Replace with your folder path\n",
    "count_files_in_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'balanced_train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/stefanberkenhoff/code/capstone-healthy-skin/notebooks/Image-loader.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/stefanberkenhoff/code/capstone-healthy-skin/notebooks/Image-loader.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m balanced_train_df\u001b[39m.\u001b[39msample(\u001b[39m15\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'balanced_train_df' is not defined"
     ]
    }
   ],
   "source": [
    "balanced_train_df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Test, Validation and Training data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train_df.to_csv('../data/processed/train_from_Metadata_processed.csv', index=False)\n",
    "validation_df.to_csv('../data/processed/validation_from_Metadata_processed.csv', index=False)\n",
    "test_df.to_csv('../data/processed/test_from_Metadata_processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
