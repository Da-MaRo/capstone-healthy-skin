{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN pretrained ResNet50 model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source of idea: https://www.ejcancer.com/article/S0959-8049(19)30349-1/fulltext#secsectitle0050 Chapter 2.2 Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrained ResNet50 CNN:\n",
    "\n",
    "* Tests have shown that adding a dropout layer to the architecture, batch size of 16 as well as regularization increased the models performance. This is included in this model as well as setting model checkpoints.\n",
    "* Thoughts on model checkpoints:\n",
    "  * model.evaluate() in Keras uses the weights of the model at the time the method is called. So if you train a model for 20 epochs and call model.evaluate() immediately after training without making any further changes to the weights, then it will use the weights from the last, 20th epoch.\n",
    "  * However, if you use a ModelCheckpoint with save_best_only=True during training, then the model's weights will only be saved if a particular metric (such as validation accuracy) improves. If you load these best weights into your model after training and then call model.evaluate(), the weights of the epoch with the best results will be used.\n",
    "  * In summary, model.evaluate() always uses the current weights of the model. It is up to you to determine which weights are loaded in the model at which point in time. This is why we should use ModelCheckpoint with save_best_only=True to evaluate the *best* model.\n",
    "* ResNet50 Model: ResNet50 is a deep convolutional neural network architecture originally designed for image classification tasks. It consists of 50 layers, including convolutional layers, batch normalization, and skip connections (residual connections), which allow it to effectively learn from very deep networks. The model is pretrained on a large dataset (typically ImageNet) to capture a wide range of features from images\n",
    "* Transfer Learning: In transfer learning, we start with a pretrained model (ResNet50 in this case) and fine-tune it for a specific task. By doing this, we leverage the knowledge the model has gained from the original dataset and adapt it to a new task, such as classifying skin lesions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Conv2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers.legacy import Adam as Adam_legacy\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from helperfunctions import modelhelper as mh\n",
    "from helperfunctions import imagehelper as ih\n",
    "\n",
    "SEED = 226\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# File path variables\n",
    "# please make sure to use the correct path to the meta data file\n",
    "\n",
    "FILEPATH_JPGS = './../data/jpgs/'\n",
    "FILEPATH_PROCESSED=\"./../data/processed/\"\n",
    "FILEPATH_OUTPUT = './../data/jpgs/'  # Replace with your folder path\n",
    "FIELPATH_TESTOUTPUT= \"./../data/testoutput/\"\n",
    "FILEPATH_MODELS = \"../models/\"\n",
    "\n",
    "MODEL_NAME = 'Resnet50_tertiary_new_setup' # please adapt according to your changes using _ and - instead of \" \"\n",
    "\n",
    "TARGET_LABEL=\"dx_tertiary\"\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "BATCH_SIZE = 16 # Adapted according to findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading (augmented) metadata as test, train, validation from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the metadata file\n",
    "train_df = pd.read_csv(FILEPATH_PROCESSED+\"train_from_Metadata_processed.csv\")\n",
    "validation_df = pd.read_csv(FILEPATH_PROCESSED+\"validation_from_Metadata_processed.csv\")\n",
    "test_df = pd.read_csv(FILEPATH_PROCESSED+\"test_from_Metadata_processed.csv\")\n",
    "\n",
    "train_df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the image data generator for training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for custom preprocessing of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_preprocessing(np_image, image_size, show_image=False):\n",
    "    # print the image\n",
    "    # print(\"From custom_preprocessing: Image + shape before preprocessing:\", np_image.shape)\n",
    "    np_image = np_image.astype(np.uint8)\n",
    "    \n",
    "    #print(np_image)\n",
    "    if show_image:\n",
    "        plt.imshow(np_image.astype(np.uint8))\n",
    "        plt.show()\n",
    "\n",
    "    # rescale \n",
    "    np_image = np_image / 255.0\n",
    "\n",
    "    # Using the image helper functions\n",
    "    np_image = ih.center_crop_image(np_image) # Crop image to square format\n",
    "    \n",
    "    if show_image:\n",
    "        print(\"From custom_preprocessing: Image after center crop:\", np_image.shape)\n",
    "        plt.imshow(np_image)\n",
    "        plt.show()\n",
    "\n",
    "    np_image = ih.resize_as_preprocess(np_image, image_size) # resize the image\n",
    "\n",
    "    if show_image:\n",
    "        print(\"From custom_preprocessing: Image after after resizing:\", np_image.shape)\n",
    "        plt.imshow(np_image)\n",
    "        plt.show()\n",
    "\n",
    "    return np_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Image generator for Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the Image Data Generator for the train data set\n",
    "\n",
    "datagen_train = ImageDataGenerator(\n",
    "    preprocessing_function=lambda x: custom_preprocessing(x, IMAGE_SIZE), # Apply the custom preprocessing function \n",
    "    horizontal_flip=True,        # Randomly flip images horizontally\n",
    "    vertical_flip=True,          # Randomly flip images vertically\n",
    "    zoom_range=0.2,              # Randomly zoom in and out by up to 20%\n",
    "    width_shift_range=0.2,       # Randomly shift images horizontally by up to 20%\n",
    "    height_shift_range=0.2,      # Randomly shift images vertically by up to 20%\n",
    "    rotation_range=30,           # Randomly rotate images by up to 30 degrees\n",
    "    shear_range=0.2,             # Shear intensity (shear angle in radians)\n",
    "    fill_mode='nearest'          # Strategy for filling in newly created pixels after transformations\n",
    ")\n",
    "\n",
    "datagen_validation = ImageDataGenerator(\n",
    "    preprocessing_function=lambda x: custom_preprocessing(x, IMAGE_SIZE)\n",
    ")\n",
    "\n",
    "train_data_generator = datagen_train.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    color_mode='rgb',\n",
    "    directory=FILEPATH_JPGS,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    #save_to_dir=FILEPATH_OUTPUT,\n",
    "    #save_prefix=\"test_gen_\",\n",
    "    #save_format=\"jpg\",\n",
    "    x_col=\"image_id\",\n",
    "    y_col=TARGET_LABEL,\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "validation_generator = datagen_validation.flow_from_dataframe(\n",
    "    dataframe=validation_df,\n",
    "    directory=FILEPATH_JPGS,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    color_mode='rgb',\n",
    "    x_col=\"image_id\",\n",
    "    y_col=TARGET_LABEL,\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control: Show some images from the train data set after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_samples(gen):\n",
    "    t_dict = gen.class_indices\n",
    "    classes = list(t_dict.keys())    \n",
    "    images, labels = next(gen)  \n",
    "    plt.figure(figsize=(25, 25))\n",
    "    length = len(labels)\n",
    "    if length < 25:  \n",
    "        r = length\n",
    "    else:\n",
    "        r = 25\n",
    "    for i in range(r):        \n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image = images[i]  \n",
    "        plt.imshow(image)\n",
    "        index = np.argmax(labels[i])\n",
    "        class_name = classes[index]\n",
    "        plt.title(class_name, color='blue', fontsize=18)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(train_data_generator)\n",
    "print(images.min(), images.max(), images.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_samples(train_data_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50 Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) # use the pretrained weights of the imagenet dataset, include_top=False means that we do not want to include the last layer of the model\n",
    "num_classes = len(train_data_generator.class_indices) \n",
    "\n",
    "# Freeze layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Add custom layers for classification\n",
    "x = base_model.output\n",
    "x = Conv2D(64, (3, 3), activation='relu',\n",
    "           kernel_regularizer=l2(0.1)\n",
    "           )(x)\n",
    "x = GlobalAveragePooling2D()(x) # GlobalAveragePooling2D reduces the spatial dimensions of the output\n",
    "  \n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.1))(x)    \n",
    "\n",
    "x = Dropout(0.5)(x)                                                 \n",
    "\n",
    "x= Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.1))(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=x, name=MODEL_NAME)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam_legacy(learning_rate=0.001), \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', mh.f1_score])\n",
    "\n",
    "# Print model summary\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate scheduler for model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a learning rate schedule function\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Learning rate schedule function.\n",
    "    \n",
    "    Args:\n",
    "        epoch (int): The current epoch number.\n",
    "        \n",
    "    Returns:\n",
    "        float: The learning rate for the current epoch.\n",
    "    \"\"\"\n",
    "    initial_lr = 0.0001  # Initial learning rate\n",
    "    drop = 0.5  # Learning rate drop factor\n",
    "    epochs_drop = 5  # Number of epochs after which learning rate will drop\n",
    "\n",
    "    # Calculate the learning rate for the current epoch\n",
    "    lr = initial_lr * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lr\n",
    "\n",
    "# Create a LearningRateScheduler callback\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Metric to monitor for early stopping\n",
    "    patience=8,         # Number of epochs with no improvement to wait before stopping\n",
    "    restore_best_weights=True  # Restore the model weights to the best epoch\n",
    "    # set range in loss function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_checkpoint = ModelCheckpoint(\n",
    "    filepath = f'{FILEPATH_MODELS}{MODEL_NAME}_best_model.h5', \n",
    "    save_best_only=True, \n",
    "    monitor='val_accuracy', \n",
    "    mode='max', \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 classes=np.unique(train_df[TARGET_LABEL]),\n",
    "                                                    y=train_df[TARGET_LABEL])\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data_generator,       # Training data generator\n",
    "    epochs=NUM_EPOCHS,          # Number of training epochs\n",
    "    verbose=1,                  # Verbosity level during training (0, 1, or 2)\n",
    "    batch_size=BATCH_SIZE,      # Batch size for training\n",
    "    callbacks=[\n",
    "        lr_scheduler, \n",
    "        early_stopping,\n",
    "        best_weights_checkpoint],\n",
    "    validation_split=0.0,       # Fraction of the training data to use as validation data (0.0 means no split)\n",
    "    validation_data=validation_generator,  # Validation data generator\n",
    "    shuffle=True,               # Shuffle the training data before each epoch\n",
    "    sample_weight=None,         # Optional sample weights for training data\n",
    "    class_weight=class_weights,  # Optional class weights for loss calculation\n",
    "    initial_epoch=0,            # Initial training epoch (useful for resuming training)\n",
    "    steps_per_epoch=None,       # Number of steps per epoch (default is len(x_train) // batch_size)\n",
    "    validation_steps=None,      # Number of steps for validation (default is len(x_val) // batch_size)\n",
    "    validation_batch_size=None,  # Batch size for validation (default is batch_size)\n",
    "    validation_freq=1,          # Frequency to validate the model on the validation set\n",
    "    max_queue_size=10,          # Maximum size of the generator queue\n",
    "    workers=-1,                 # Maximum number of processes to generate data in parallel (-1 means all CPUs)\n",
    "    use_multiprocessing=False   # Use multiprocessing for data generation (True or False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting accuracy and loss of train and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Accuracy  of train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting accuracy of train and validation\n",
    "mh.model_plot_accuracy(history)\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score of train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a variable named 'history' containing the training history\n",
    "# (e.g., history = model.fit(...) where model is your Keras model)\n",
    "# You can access the loss values from 'history.history'\n",
    "\n",
    "# Plot the loss functions\n",
    "plt.plot(history.history['f1_score'], label='Training F1 Score')\n",
    "plt.plot(history.history['val_f1_score'], label='Validation F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim([0, 1])  # Set the y-axis limits as needed\n",
    "plt.legend(loc='lower right')  # You can adjust the legend position\n",
    "plt.show()  # Show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Loss of train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0, 3])  # Set the y-axis limits as needed\n",
    "plt.legend(loc='upper right')  # You can adjust the legend position\n",
    "plt.show()  # Show the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh.model_accuracy_on_test(model, test_df, TARGET_LABEL, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now()\n",
    "model_path = f\"{FILEPATH_MODELS}model_{timestamp}.h5\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Continue training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training for another 10 epochs\n",
    "additional_epochs = 10\n",
    "continue_training = False\n",
    "\n",
    "if continue_training:\n",
    "    history_continued = model.fit(\n",
    "        train_data_generator,\n",
    "        steps_per_epoch=None,\n",
    "        epochs=NUM_EPOCHS + additional_epochs,\n",
    "        initial_epoch=NUM_EPOCHS,  # start from the epoch after your last training session\n",
    "        validation_data=validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if continue_training:\n",
    "    mh.model_plot_accuracy(history_continued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if continue_training:\n",
    "    mh.model_accuracy_on_test(model, test_df, TARGET_LABEL, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if continue_training:\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now()\n",
    "    model_path = f\"../models/model_{timestamp}.h5\"\n",
    "    model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
