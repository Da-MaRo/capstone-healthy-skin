{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and inital setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from helperfunctions import modelhelper as mh\n",
    "\n",
    "SEED = 42\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "# File path variables\n",
    "# please make sure to use the correct path to the meta data file\n",
    "\n",
    "FILEPATH_JPGS = './../data/jpgs/'\n",
    "FILEPATH_PROCESSED=\"./../data/processed/\"\n",
    "FILEPATH_OUTPUT = './../data/jpgs/'  # Replace with your folder path\n",
    "\n",
    "TARGET_LABEL=\"dx\"\n",
    "BALANCE_LABEL=\"dx\"\n",
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading (augmented) metadata as test, train, validation from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dx_binary</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>HAM_0000757</td>\n",
       "      <td>aug_6Hs26eISIC_0025314.jpg</td>\n",
       "      <td>df</td>\n",
       "      <td>consensus</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/aug_6Hs26eISIC_0025314.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>HAM_0004257</td>\n",
       "      <td>aug_MOpYJfISIC_0025452.jpg</td>\n",
       "      <td>vasc</td>\n",
       "      <td>consensus</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/aug_MOpYJfISIC_0025452.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>HAM_0001927</td>\n",
       "      <td>ISIC_0029600.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vienna_dias</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0029600.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>HAM_0002042</td>\n",
       "      <td>ISIC_0031349.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>confocal</td>\n",
       "      <td>75.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0031349.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>HAM_0003610</td>\n",
       "      <td>ISIC_0028937.jpg</td>\n",
       "      <td>bcc</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0028937.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>HAM_0004943</td>\n",
       "      <td>aug_ekkoRzISIC_0027790.jpg</td>\n",
       "      <td>vasc</td>\n",
       "      <td>consensus</td>\n",
       "      <td>50.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/aug_ekkoRzISIC_0027790.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>HAM_0000643</td>\n",
       "      <td>ISIC_0029731.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0029731.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>HAM_0003189</td>\n",
       "      <td>ISIC_0027324.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0027324.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>HAM_0002169</td>\n",
       "      <td>ISIC_0031593.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0031593.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>HAM_0005981</td>\n",
       "      <td>ISIC_0027371.jpg</td>\n",
       "      <td>bcc</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0027371.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>HAM_0007396</td>\n",
       "      <td>ISIC_0033554.jpg</td>\n",
       "      <td>df</td>\n",
       "      <td>consensus</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0033554.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>HAM_0005088</td>\n",
       "      <td>ISIC_0031647.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>50.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0031647.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>HAM_0005701</td>\n",
       "      <td>ISIC_0025350.jpg</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0025350.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>HAM_0001137</td>\n",
       "      <td>ISIC_0029746.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>vienna_dias</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0029746.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>HAM_0007027</td>\n",
       "      <td>ISIC_0026967.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0026967.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id                    image_id     dx    dx_type   age     sex   \n",
       "1289  HAM_0000757  aug_6Hs26eISIC_0025314.jpg     df  consensus  35.0  female  \\\n",
       "947   HAM_0004257  aug_MOpYJfISIC_0025452.jpg   vasc  consensus  55.0  female   \n",
       "1192  HAM_0001927            ISIC_0029600.jpg    bkl      histo  85.0  female   \n",
       "1080  HAM_0002042            ISIC_0031349.jpg    bkl   confocal  75.0  female   \n",
       "262   HAM_0003610            ISIC_0028937.jpg    bcc      histo  80.0    male   \n",
       "888   HAM_0004943  aug_ekkoRzISIC_0027790.jpg   vasc  consensus  50.0  female   \n",
       "1028  HAM_0000643            ISIC_0029731.jpg    bkl  consensus  75.0    male   \n",
       "44    HAM_0003189            ISIC_0027324.jpg     nv  follow_up  45.0  female   \n",
       "1082  HAM_0002169            ISIC_0031593.jpg    bkl      histo  65.0    male   \n",
       "230   HAM_0005981            ISIC_0027371.jpg    bcc      histo  65.0    male   \n",
       "1265  HAM_0007396            ISIC_0033554.jpg     df  consensus  35.0  female   \n",
       "22    HAM_0005088            ISIC_0031647.jpg     nv  follow_up  50.0  female   \n",
       "720   HAM_0005701            ISIC_0025350.jpg  akiec      histo  70.0    male   \n",
       "62    HAM_0001137            ISIC_0029746.jpg     nv      histo  60.0  female   \n",
       "1081  HAM_0007027            ISIC_0026967.jpg    bkl  consensus  75.0  female   \n",
       "\n",
       "         localization        dataset        dx_binary   \n",
       "1289  lower extremity  vidir_molemax  not_skin_cancer  \\\n",
       "947           abdomen  vidir_molemax  not_skin_cancer   \n",
       "1192          abdomen    vienna_dias  not_skin_cancer   \n",
       "1080             face   vidir_modern  not_skin_cancer   \n",
       "262              face      rosendahl      skin_cancer   \n",
       "888              face  vidir_molemax  not_skin_cancer   \n",
       "1028             face  vidir_molemax  not_skin_cancer   \n",
       "44    lower extremity  vidir_molemax  not_skin_cancer   \n",
       "1082  upper extremity      rosendahl  not_skin_cancer   \n",
       "230              face      rosendahl      skin_cancer   \n",
       "1265  lower extremity   vidir_modern  not_skin_cancer   \n",
       "22              trunk  vidir_molemax  not_skin_cancer   \n",
       "720   lower extremity      rosendahl      skin_cancer   \n",
       "62              chest    vienna_dias  not_skin_cancer   \n",
       "1081             back  vidir_molemax  not_skin_cancer   \n",
       "\n",
       "                                     image_path  \n",
       "1289  ./../data/jpgs/aug_6Hs26eISIC_0025314.jpg  \n",
       "947   ./../data/jpgs/aug_MOpYJfISIC_0025452.jpg  \n",
       "1192            ./../data/jpgs/ISIC_0029600.jpg  \n",
       "1080            ./../data/jpgs/ISIC_0031349.jpg  \n",
       "262             ./../data/jpgs/ISIC_0028937.jpg  \n",
       "888   ./../data/jpgs/aug_ekkoRzISIC_0027790.jpg  \n",
       "1028            ./../data/jpgs/ISIC_0029731.jpg  \n",
       "44              ./../data/jpgs/ISIC_0027324.jpg  \n",
       "1082            ./../data/jpgs/ISIC_0031593.jpg  \n",
       "230             ./../data/jpgs/ISIC_0027371.jpg  \n",
       "1265            ./../data/jpgs/ISIC_0033554.jpg  \n",
       "22              ./../data/jpgs/ISIC_0031647.jpg  \n",
       "720             ./../data/jpgs/ISIC_0025350.jpg  \n",
       "62              ./../data/jpgs/ISIC_0029746.jpg  \n",
       "1081            ./../data/jpgs/ISIC_0026967.jpg  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the metadata file\n",
    "train_df = pd.read_csv(FILEPATH_PROCESSED+\"train_from_Metadata_processed.csv\")\n",
    "validation_df = pd.read_csv(FILEPATH_PROCESSED+\"validation_from_Metadata_processed.csv\")\n",
    "test_df = pd.read_csv(FILEPATH_PROCESSED+\"test_from_Metadata_processed.csv\")\n",
    "\n",
    "train_df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the image data generator for training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: each Keras Application expects a specific kind of input preprocessing. For VGG16, call tf.keras.applications.vgg16.preprocess_input on your inputs before passing them to the model. vgg16.preprocess_input will convert the input images from RGB to BGR, then will zero-center each color channel with respect to the ImageNet dataset, without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2003 validated image filenames belonging to 7 classes.\n",
      "Found 1403 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Setting up the Image Data Generator for the train data set - including augmentation\n",
    "\n",
    "\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,  # Rescale pixel values to [0, 1], important for CNNs to perform better, deactivate to see images down below\n",
    "    preprocessing_function=preprocess_input,  # VGG16 specific preprocessing\n",
    ")\n",
    "\n",
    "datagen_validation = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0, #see above\n",
    "    preprocessing_function=preprocess_input,  # VGG16 specific preprocessing\n",
    ")\n",
    "\n",
    "validation_generator = datagen_validation.flow_from_dataframe(\n",
    "    dataframe=validation_df,\n",
    "    directory=FILEPATH_JPGS,\n",
    "    x_col=\"image_id\",\n",
    "    y_col=TARGET_LABEL,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "train_data_generator = datagen_train.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=FILEPATH_JPGS,\n",
    "        x_col=\"image_id\",\n",
    "        y_col=TARGET_LABEL,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding an neural network model to test the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 Model\n",
    "The VGG16 is a pre-trained Convolutional Neural Network (CNN) model proposed by K. Simonyan and A. Zisserman from the University of Oxford's Visual Geometry Group Lab. The model was proposed in their 2014 paper \"Very Deep Convolutional Networks for Large-Scale Image Recognition\" and won the 1st and 2nd places in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2014 geeksforgeeks.org. It is considered one of the best vision model architectures to date due to its simplicity and high performance builtin.com.\n",
    "\n",
    "[Source:Tensorflow Applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/VGG16)\n",
    "\n",
    "Architecture:\n",
    "\n",
    "*Input:*\n",
    "\n",
    "Conv 1-1,\n",
    "Conv 1-2,\n",
    "Pooling\n",
    "\n",
    "Conv 2-1,\n",
    "Conv 2-2,\n",
    "Pooling\n",
    "\n",
    "Conv 3-1,\n",
    "Conv 3-2,\n",
    "Conv 3-3,\n",
    "Pooling\n",
    "\n",
    "Conv 4-1,\n",
    "Conv 4-2,\n",
    "Conv 4-3,\n",
    "Pooling\n",
    "\n",
    "Conv 5-1,\n",
    "Conv 5-2,\n",
    "Conv 5-3,\n",
    "Pooling\n",
    "\n",
    "Dense,\n",
    "Dense,\n",
    "Dense\n",
    "\n",
    "*Output*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the VGG16 model\n",
    "vgg16_model = VGG16(\n",
    "    include_top=False, # do not include the top layer, we will add our own\n",
    "    weights= \"imagenet\", # use the weights that the model was trained on\n",
    "    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), # the input shape of the images (3 channels, width, height)\n",
    "    pooling=\"avg\", # the type of pooling to use when we add the top layer (average pooling)\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    vgg16_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'), # the number of neurons in the top layer\n",
    "    tf.keras.layers.Dense(256, activation='relu'), # the number of neurons in the 2nd top layer\n",
    "    tf.keras.layers.Dense(7, activation='softmax') # the number of classes we want to predict\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 512)               14714688  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2048)              1050624   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17870663 (68.17 MB)\n",
      "Trainable params: 17870663 (68.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "44/44 [==============================] - 916s 21s/step - loss: 2.1466 - accuracy: 0.1390 - val_loss: 1.9762 - val_accuracy: 0.0325\n",
      "Epoch 2/2\n",
      "10/44 [=====>........................] - ETA: 7:58 - loss: 1.9455 - accuracy: 0.1469"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16 _cnn.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train_data_generator,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mNUM_EPOCHS,              \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,                      \u001b[39m# Adjust verbosity level\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,                \u001b[39m# Set the batch size, default is 32, can be increased to speed up training\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,                 \u001b[39m# List of callbacks to apply during training \u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,           \u001b[39m# not needed as we use a validation data generator\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,                   \u001b[39m# Shuffle the training data before each epoch\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     sample_weight\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,             \u001b[39m# Set the weights for the train data set !\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,              \u001b[39m# Set the weights for the classes, not needed if we use sample weights\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,                \u001b[39m# Use this to continue training from a specific epoch\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,           \u001b[39m# Set the number of steps per epoch, default is len(x_train) // batch_size\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,          \u001b[39m# Set the number of steps for validation, default is len(x_val) // batch_size\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     validation_batch_size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,     \u001b[39m# Set the batch size for validation, default is batch_size\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     validation_freq\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,              \u001b[39m# Only relevant if validation data is a generator. Set the frequency to validate the model on the validation set\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,              \u001b[39m# Set the max size for the generator queue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     workers\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,                     \u001b[39m# Set the max number of processes to generate the data in parallel, -1 means all CPUs\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m       \u001b[39m# Set to True if you use a generator in parallel, e.g. model.predict_generator()\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "history = model.fit(\n",
    "    train_data_generator,\n",
    "    epochs=NUM_EPOCHS,              \n",
    "    verbose=1,                      # Adjust verbosity level\n",
    "    batch_size=None,                # Set the batch size, default is 32, can be increased to speed up training\n",
    "    callbacks=None,                 # List of callbacks to apply during training \n",
    "    validation_split=0.0,           # not needed as we use a validation data generator\n",
    "    validation_data=validation_generator,\n",
    "    shuffle=True,                   # Shuffle the training data before each epoch\n",
    "    sample_weight=None,             # Set the weights for the train data set !\n",
    "    class_weight=None,              # Set the weights for the classes, not needed if we use sample weights\n",
    "    initial_epoch=0,                # Use this to continue training from a specific epoch\n",
    "    steps_per_epoch=None,           # Set the number of steps per epoch, default is len(x_train) // batch_size\n",
    "    validation_steps=None,          # Set the number of steps for validation, default is len(x_val) // batch_size\n",
    "    validation_batch_size=None,     # Set the batch size for validation, default is batch_size\n",
    "    validation_freq=1,              # Only relevant if validation data is a generator. Set the frequency to validate the model on the validation set\n",
    "    max_queue_size=10,              # Set the max size for the generator queue\n",
    "    workers=-1,                     # Set the max number of processes to generate the data in parallel, -1 means all CPUs\n",
    "    use_multiprocessing=False       # Set to True if you use a generator in parallel, e.g. model.predict_generator()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting accuracy and loss of train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mh.model_plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16 _cnn.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/da.ma.ro/Documents/Capstone/capstone-healthy-skin/tensorflow/VGG16%20_cnn.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mh\u001b[39m.\u001b[39;49mmodel_accuracy_on_test(model, test_df, TARGET_LABEL, IMAGE_SIZE)\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/tensorflow/../helperfunctions/modelhelper.py:52\u001b[0m, in \u001b[0;36mmodel_accuracy_on_test\u001b[0;34m(model, test_df, targetvar, imagesize)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m# reshaping the test images\u001b[39;00m\n\u001b[1;32m     50\u001b[0m test_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(test_images)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, imagesize[\u001b[39m0\u001b[39m], imagesize[\u001b[39m1\u001b[39m], \u001b[39m3\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(test_images, test_labels, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:2200\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2196\u001b[0m             \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2197\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2198\u001b[0m             ):\n\u001b[1;32m   2199\u001b[0m                 callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2200\u001b[0m                 logs \u001b[39m=\u001b[39m test_function_runner\u001b[39m.\u001b[39;49mrun_step(\n\u001b[1;32m   2201\u001b[0m                     dataset_or_iterator,\n\u001b[1;32m   2202\u001b[0m                     data_handler,\n\u001b[1;32m   2203\u001b[0m                     step,\n\u001b[1;32m   2204\u001b[0m                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pss_evaluation_shards,\n\u001b[1;32m   2205\u001b[0m                 )\n\u001b[1;32m   2207\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2208\u001b[0m \u001b[39m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:4000\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   3999\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(\u001b[39mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4000\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function(dataset_or_iterator)\n\u001b[1;32m   4001\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   4002\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:864\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    862\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    865\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    866\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/Capstone/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mh.model_accuracy_on_test(model, test_df, TARGET_LABEL, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefanberkenhoff/code/capstone-healthy-skin/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now()\n",
    "model_path = f\"../models/model_{timestamp}.h5\"\n",
    "model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
