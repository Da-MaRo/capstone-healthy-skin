{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tryout Notebook for ResNet50 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source of idea: https://www.ejcancer.com/article/S0959-8049(19)30349-1/fulltext#secsectitle0050 Chapter 2.2 Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrained ResNet50 CNN:\n",
    "\n",
    "* ResNet50 Model: ResNet50 is a deep convolutional neural network architecture originally designed for image classification tasks. It consists of 50 layers, including convolutional layers, batch normalization, and skip connections (residual connections), which allow it to effectively learn from very deep networks. The model is pretrained on a large dataset (typically ImageNet) to capture a wide range of features from images\n",
    "\n",
    "* Transfer Learning: In transfer learning, we start with a pretrained model (ResNet50 in this case) and fine-tune it for a specific task. By doing this, we leverage the knowledge the model has gained from the original dataset and adapt it to a new task, such as classifying skin lesions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and inital setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from helperfunctions import modelhelper as mh\n",
    "\n",
    "SEED = 42\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# File path variables\n",
    "# please make sure to use the correct path to the meta data file\n",
    "\n",
    "FILEPATH_JPGS = './../data/jpgs/'\n",
    "FILEPATH_PROCESSED=\"./../data/processed/\"\n",
    "FILEPATH_OUTPUT = './../data/jpgs/'  # Replace with your folder path\n",
    "\n",
    "TARGET_LABEL=\"dx\"\n",
    "BALANCE_LABEL=\"dx\"\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading (augmented) metadata as test, train, validation from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dx_binary</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>HAM_0006805</td>\n",
       "      <td>ISIC_0029772.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0029772.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>HAM_0004620</td>\n",
       "      <td>ISIC_0033122.jpg</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>trunk</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0033122.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>HAM_0005918</td>\n",
       "      <td>aug_rXxrCtISIC_0029177.jpg</td>\n",
       "      <td>df</td>\n",
       "      <td>consensus</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/aug_rXxrCtISIC_0029177.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>HAM_0002450</td>\n",
       "      <td>ISIC_0024396.jpg</td>\n",
       "      <td>df</td>\n",
       "      <td>consensus</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0024396.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>HAM_0006852</td>\n",
       "      <td>aug_ozCklkISIC_0032715.jpg</td>\n",
       "      <td>vasc</td>\n",
       "      <td>consensus</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/aug_ozCklkISIC_0032715.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>HAM_0004791</td>\n",
       "      <td>aug_XalNoFISIC_0033135.jpg</td>\n",
       "      <td>vasc</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/aug_XalNoFISIC_0033135.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>HAM_0004153</td>\n",
       "      <td>ISIC_0026489.jpg</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>foot</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0026489.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>HAM_0005533</td>\n",
       "      <td>ISIC_0027065.jpg</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0027065.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>HAM_0005409</td>\n",
       "      <td>ISIC_0032970.jpg</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>45.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0032970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>HAM_0002749</td>\n",
       "      <td>ISIC_0025066.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0025066.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>HAM_0003015</td>\n",
       "      <td>ISIC_0032456.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0032456.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>HAM_0002134</td>\n",
       "      <td>ISIC_0026656.jpg</td>\n",
       "      <td>bcc</td>\n",
       "      <td>histo</td>\n",
       "      <td>45.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0026656.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>HAM_0006324</td>\n",
       "      <td>aug_vi0xljISIC_0029889.jpg</td>\n",
       "      <td>vasc</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/aug_vi0xljISIC_0029889.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>HAM_0001785</td>\n",
       "      <td>aug_rDot2SISIC_0032941.jpg</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>not_skin_cancer</td>\n",
       "      <td>./../data/jpgs/aug_rDot2SISIC_0032941.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>HAM_0006130</td>\n",
       "      <td>ISIC_0031670.jpg</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>female</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>skin_cancer</td>\n",
       "      <td>./../data/jpgs/ISIC_0031670.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id                    image_id    dx    dx_type   age     sex   \n",
       "173   HAM_0006805            ISIC_0029772.jpg    nv  follow_up  50.0    male  \\\n",
       "1170  HAM_0004620            ISIC_0033122.jpg   mel      histo  55.0    male   \n",
       "3212  HAM_0005918  aug_rXxrCtISIC_0029177.jpg    df  consensus  35.0  female   \n",
       "3054  HAM_0002450            ISIC_0024396.jpg    df  consensus  65.0  female   \n",
       "2373  HAM_0006852  aug_ozCklkISIC_0032715.jpg  vasc  consensus  45.0  female   \n",
       "2262  HAM_0004791  aug_XalNoFISIC_0033135.jpg  vasc      histo  80.0  female   \n",
       "1011  HAM_0004153            ISIC_0026489.jpg   mel      histo  80.0    male   \n",
       "1407  HAM_0005533            ISIC_0027065.jpg   mel      histo  85.0  female   \n",
       "1462  HAM_0005409            ISIC_0032970.jpg   mel      histo  45.0    male   \n",
       "2611  HAM_0002749            ISIC_0025066.jpg   bkl      histo  60.0    male   \n",
       "2988  HAM_0003015            ISIC_0032456.jpg   bkl      histo  55.0    male   \n",
       "506   HAM_0002134            ISIC_0026656.jpg   bcc      histo  45.0    male   \n",
       "2397  HAM_0006324  aug_vi0xljISIC_0029889.jpg  vasc      histo  40.0  female   \n",
       "3391  HAM_0001785  aug_rDot2SISIC_0032941.jpg    df      histo  50.0    male   \n",
       "1010  HAM_0006130            ISIC_0031670.jpg   mel      histo  80.0  female   \n",
       "\n",
       "         localization        dataset        dx_binary   \n",
       "173              back  vidir_molemax  not_skin_cancer  \\\n",
       "1170            trunk   vidir_modern      skin_cancer   \n",
       "3212  lower extremity  vidir_molemax  not_skin_cancer   \n",
       "3054  lower extremity   vidir_modern  not_skin_cancer   \n",
       "2373          abdomen   vidir_modern  not_skin_cancer   \n",
       "2262  lower extremity   vidir_modern  not_skin_cancer   \n",
       "1011             foot   vidir_modern      skin_cancer   \n",
       "1407  upper extremity      rosendahl      skin_cancer   \n",
       "1462             back   vidir_modern      skin_cancer   \n",
       "2611  upper extremity      rosendahl  not_skin_cancer   \n",
       "2988             back      rosendahl  not_skin_cancer   \n",
       "506              face   vidir_modern      skin_cancer   \n",
       "2397            chest   vidir_modern  not_skin_cancer   \n",
       "3391  upper extremity   vidir_modern  not_skin_cancer   \n",
       "1010  upper extremity      rosendahl      skin_cancer   \n",
       "\n",
       "                                     image_path  \n",
       "173             ./../data/jpgs/ISIC_0029772.jpg  \n",
       "1170            ./../data/jpgs/ISIC_0033122.jpg  \n",
       "3212  ./../data/jpgs/aug_rXxrCtISIC_0029177.jpg  \n",
       "3054            ./../data/jpgs/ISIC_0024396.jpg  \n",
       "2373  ./../data/jpgs/aug_ozCklkISIC_0032715.jpg  \n",
       "2262  ./../data/jpgs/aug_XalNoFISIC_0033135.jpg  \n",
       "1011            ./../data/jpgs/ISIC_0026489.jpg  \n",
       "1407            ./../data/jpgs/ISIC_0027065.jpg  \n",
       "1462            ./../data/jpgs/ISIC_0032970.jpg  \n",
       "2611            ./../data/jpgs/ISIC_0025066.jpg  \n",
       "2988            ./../data/jpgs/ISIC_0032456.jpg  \n",
       "506             ./../data/jpgs/ISIC_0026656.jpg  \n",
       "2397  ./../data/jpgs/aug_vi0xljISIC_0029889.jpg  \n",
       "3391  ./../data/jpgs/aug_rDot2SISIC_0032941.jpg  \n",
       "1010            ./../data/jpgs/ISIC_0031670.jpg  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the metadata file\n",
    "train_df = pd.read_csv(FILEPATH_PROCESSED+\"train_from_Metadata_processed.csv\")\n",
    "validation_df = pd.read_csv(FILEPATH_PROCESSED+\"validation_from_Metadata_processed.csv\")\n",
    "test_df = pd.read_csv(FILEPATH_PROCESSED+\"test_from_Metadata_processed.csv\")\n",
    "\n",
    "train_df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the image data generator for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2003 validated image filenames belonging to 7 classes.\n",
      "Found 3504 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Setting up the Image Data Generator for the train data set - including augmentation\n",
    "\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,  # Rescale pixel values to [0, 1], important for CNNs to perform better, deactivate to see images down below\n",
    ")\n",
    "\n",
    "datagen_validation = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0 #see above\n",
    ")\n",
    "\n",
    "validation_generator = datagen_validation.flow_from_dataframe(\n",
    "    dataframe=validation_df,\n",
    "    directory=FILEPATH_JPGS,\n",
    "    x_col=\"image_id\",\n",
    "    y_col=TARGET_LABEL,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "train_data_generator = datagen_train.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=FILEPATH_JPGS,\n",
    "        x_col=\"image_id\",\n",
    "        y_col=TARGET_LABEL,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, None, None, 3)        0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, None, None, 64)       9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalizati  (None, None, None, 64)       256       ['conv1_conv[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)     (None, None, None, 64)       0         ['conv1_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, None, None, 64)       0         ['conv1_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, None, None, 64)       0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, None, None, 64)       4160      ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, None, None, 256)      16640     ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)      (None, None, None, 256)      0         ['conv2_block1_0_bn[0][0]',   \n",
      "                                                                     'conv2_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activati  (None, None, None, 256)      0         ['conv2_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, None, None, 64)       16448     ['conv2_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)      (None, None, None, 256)      0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activati  (None, None, None, 256)      0         ['conv2_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, None, None, 64)       16448     ['conv2_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)      (None, None, None, 256)      0         ['conv2_block2_out[0][0]',    \n",
      "                                                                     'conv2_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activati  (None, None, None, 256)      0         ['conv2_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, None, None, 128)      32896     ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, None, None, 512)      131584    ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)      (None, None, None, 512)      0         ['conv3_block1_0_bn[0][0]',   \n",
      "                                                                     'conv3_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activati  (None, None, None, 512)      0         ['conv3_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)      (None, None, None, 512)      0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activati  (None, None, None, 512)      0         ['conv3_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)      (None, None, None, 512)      0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activati  (None, None, None, 512)      0         ['conv3_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)      (None, None, None, 512)      0         ['conv3_block3_out[0][0]',    \n",
      "                                                                     'conv3_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activati  (None, None, None, 512)      0         ['conv3_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, None, None, 256)      131328    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, None, None, 1024)     525312    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)      (None, None, None, 1024)     0         ['conv4_block1_0_bn[0][0]',   \n",
      "                                                                     'conv4_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activati  (None, None, None, 1024)     0         ['conv4_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)      (None, None, None, 1024)     0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activati  (None, None, None, 1024)     0         ['conv4_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)      (None, None, None, 1024)     0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activati  (None, None, None, 1024)     0         ['conv4_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)      (None, None, None, 1024)     0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activati  (None, None, None, 1024)     0         ['conv4_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block5_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)      (None, None, None, 1024)     0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activati  (None, None, None, 1024)     0         ['conv4_block5_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block5_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block6_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)      (None, None, None, 1024)     0         ['conv4_block5_out[0][0]',    \n",
      "                                                                     'conv4_block6_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activati  (None, None, None, 1024)     0         ['conv4_block6_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, None, None, 512)      524800    ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, None, None, 2048)     2099200   ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)      (None, None, None, 2048)     0         ['conv5_block1_0_bn[0][0]',   \n",
      "                                                                     'conv5_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activati  (None, None, None, 2048)     0         ['conv5_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, None, None, 512)      1049088   ['conv5_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)      (None, None, None, 2048)     0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activati  (None, None, None, 2048)     0         ['conv5_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, None, None, 512)      1049088   ['conv5_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)      (None, None, None, 2048)     0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activati  (None, None, None, 2048)     0         ['conv5_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 2048)                 0         ['conv5_block3_out[0][0]']    \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 2098176   ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 7)                    7175      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25693063 (98.01 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 25693063 (98.01 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "import math\n",
    "\n",
    "# Create a base ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False) # use the pretrained weights of the imagenet dataset, include_top=False means that we do not want to include the last layer of the model\n",
    "num_classes = len(train_data_generator.class_indices) \n",
    "\n",
    "# Add custom layers for classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x) # GlobalAveragePooling2D reduces the spatial dimensions of the output\n",
    "x = Dense(1024, activation='relu')(x) # fully connected layer with 1024 neurons and ReLU activation, relu is used to introduce non-linearity\n",
    "predictions = Dense(num_classes, activation='softmax')(x) #  output layer with a number of neurons equal to the number of classes (determined by num_classes) and a softmax activation function for multi-class classification.\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "# Freeze all layers in the entire model\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "# Define differential learning rates for different layers\n",
    "lr_rates = {\n",
    "    'dense_1': 1e-3,  # Adjust the learning rate for the dense layer\n",
    "    'dense_2': 1e-4,  # Adjust the learning rate for the output layer\n",
    "}\n",
    "\n",
    "# Implement learning rate scheduler with cosine annealing\n",
    "def cosine_annealing(epoch):\n",
    "    max_lr = lr_rates['dense_1']\n",
    "    min_lr = lr_rates['dense_2']\n",
    "    total_epochs = 10  # Adjust the total number of epochs\n",
    "    cos_val = (1 + math.cos(math.pi * epoch / total_epochs)) / 2\n",
    "    return min_lr + (max_lr - min_lr) * cos_val\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(cosine_annealing) # Applying a Learning rate scheduler\n",
    "\n",
    "# Compile the model with a custom optimizer (SGD with momentum)\n",
    "custom_optimizer = tf.keras.optimizers.SGD(lr=1e-2, momentum=0.9)\n",
    "model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Define checkpoints to save the best model\n",
    "#checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "110/110 [==============================] - 205s 2s/step - loss: 2.3014 - accuracy: 0.1430 - val_loss: 2.5779 - val_accuracy: 0.0514 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 220s 2s/step - loss: 2.3014 - accuracy: 0.1430 - val_loss: 2.5779 - val_accuracy: 0.0514 - lr: 9.7798e-04\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 221s 2s/step - loss: 2.3014 - accuracy: 0.1430 - val_loss: 2.5779 - val_accuracy: 0.0514 - lr: 9.1406e-04\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 223s 2s/step - loss: 2.3014 - accuracy: 0.1430 - val_loss: 2.5779 - val_accuracy: 0.0514 - lr: 8.1450e-04\n",
      "Epoch 5/10\n",
      " 52/110 [=============>................] - ETA: 1:11 - loss: 2.2921 - accuracy: 0.1475"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train_data_generator,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mNUM_EPOCHS,              \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,                      \u001b[39m# Adjust verbosity level\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE,                \u001b[39m# Set the batch size, default is 32, can be increased to speed up training, but memory consumption increases\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[lr_scheduler],                 \u001b[39m# List of callbacks to apply during training \u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,           \u001b[39m# not needed as we use a validation data generator\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,                   \u001b[39m# Shuffle the training data before each epoch\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     sample_weight\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,             \u001b[39m# Set the weights for the train data set !\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,              \u001b[39m# Set the weights for the classes, not needed if we use sample weights\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,                \u001b[39m# Use this to continue training from a specific epoch\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,           \u001b[39m# Set the number of steps per epoch, default is len(x_train) // batch_size\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,          \u001b[39m# Set the number of steps for validation, default is len(x_val) // batch_size\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     validation_batch_size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,     \u001b[39m# Set the batch size for validation, default is batch_size\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     validation_freq\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,              \u001b[39m# Only relevant if validation data is a generator. Set the frequency to validate the model on the validation set\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,              \u001b[39m# Set the max size for the generator queue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     workers\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,                     \u001b[39m# Set the max number of processes to generate the data in parallel, -1 means all CPUs\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m       \u001b[39m# Set to True if you use a generator in parallel, e.g. model.predict_generator()\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/tensorflow/1_resnet50_1.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/neuefische/capstone-healthy-skin/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/neuefische/capstone-healthy-skin/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Documents/neuefische/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/neuefische/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/neuefische/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Documents/neuefische/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Documents/neuefische/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/neuefische/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/Documents/neuefische/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/neuefische/capstone-healthy-skin/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "history = model.fit(\n",
    "    train_data_generator,\n",
    "    epochs=NUM_EPOCHS,              \n",
    "    verbose=1,                      # Adjust verbosity level\n",
    "    batch_size=BATCH_SIZE,                # Set the batch size, default is 32, can be increased to speed up training, but memory consumption increases\n",
    "    callbacks=[lr_scheduler],                 # List of callbacks to apply during training \n",
    "    validation_split=0.0,           # not needed as we use a validation data generator\n",
    "    validation_data=validation_generator,\n",
    "    shuffle=True,                   # Shuffle the training data before each epoch\n",
    "    sample_weight=None,             # Set the weights for the train data set !\n",
    "    class_weight=None,              # Set the weights for the classes, not needed if we use sample weights\n",
    "    initial_epoch=0,                # Use this to continue training from a specific epoch\n",
    "    steps_per_epoch=None,           # Set the number of steps per epoch, default is len(x_train) // batch_size\n",
    "    validation_steps=None,          # Set the number of steps for validation, default is len(x_val) // batch_size\n",
    "    validation_batch_size=None,     # Set the batch size for validation, default is batch_size\n",
    "    validation_freq=1,              # Only relevant if validation data is a generator. Set the frequency to validate the model on the validation set\n",
    "    max_queue_size=10,              # Set the max size for the generator queue\n",
    "    workers=-1,                     # Set the max number of processes to generate the data in parallel, -1 means all CPUs\n",
    "    use_multiprocessing=False       # Set to True if you use a generator in parallel, e.g. model.predict_generator()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting accuracy and loss of train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mh.model_plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 92s - loss: 1.8327 - accuracy: 0.2292 - 92s/epoch - 1s/step\n"
     ]
    }
   ],
   "source": [
    "mh.model_accuracy_on_test(model, test_df, TARGET_LABEL, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(y_test, y_pred):\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 10})\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report(test_df, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janicepelzer/Documents/neuefische/capstone-healthy-skin/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now()\n",
    "model_path = f\"../models/model_{timestamp}.h5\"\n",
    "model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
