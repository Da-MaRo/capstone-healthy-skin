{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a template for building a CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and inital setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from helperfunctions import modelhelper as mh\n",
    "from helperfunctions import imagehelper as ih\n",
    "\n",
    "SEED = 856\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "# File path variables\n",
    "# please make sure to use the correct path to the meta data file\n",
    "\n",
    "FILEPATH_JPGS = './../data/jpgs/'\n",
    "FILEPATH_PROCESSED=\"./../data/processed/\"\n",
    "FILEPATH_OUTPUT = './../data/jpgs/'  # Replace with your folder path\n",
    "\n",
    "TARGET_LABEL=\"dx_binary\"\n",
    "\n",
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading (augmented) metadata as test, train, validation from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the metadata file\n",
    "train_df = pd.read_csv(FILEPATH_PROCESSED+\"train_from_Metadata_processed.csv\")\n",
    "validation_df = pd.read_csv(FILEPATH_PROCESSED+\"validation_from_Metadata_processed.csv\")\n",
    "test_df = pd.read_csv(FILEPATH_PROCESSED+\"test_from_Metadata_processed.csv\")\n",
    "\n",
    "train_df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the image data generator for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_preprocessing(np_image, image_size):\n",
    "    np_image = ih.center_crop_image(np_image) # Crop image to square format\n",
    "    np_image = ih.resize_as_preprocess(np_image, image_size) # resize the image\n",
    "    np_image = preprocess_input(np_image) # Apply the preprocess_input function of MobileNetV3Large\n",
    "    return np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the Image Data Generator for the train data set\n",
    "\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0, # Rescale pixel values to [0, 1], important for CNNs to perform better\n",
    "    preprocessing_function=lambda x: custom_preprocessing(x, IMAGE_SIZE), # Apply the custom preprocessing function \n",
    ")\n",
    "\n",
    "datagen_validation = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    preprocessing_function=lambda x: custom_preprocessing(x, IMAGE_SIZE)\n",
    ")\n",
    "\n",
    "validation_generator = datagen_validation.flow_from_dataframe(\n",
    "    dataframe=validation_df,\n",
    "    directory=FILEPATH_JPGS,\n",
    "    x_col=\"image_id\",\n",
    "    y_col=TARGET_LABEL,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "train_data_generator = datagen_train.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=FILEPATH_JPGS,\n",
    "        x_col=\"image_id\",\n",
    "        y_col=TARGET_LABEL,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MobileNet V3 large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED = True\n",
    "\n",
    "if PRETRAINED:\n",
    "    # Initialize the MobileNetV3Large model\n",
    "    base_model = MobileNetV3Large(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "\n",
    "    # Freeze the base model's layers to use it for feature extraction\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers on top \n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu')(base_model.output)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(train_df[TARGET_LABEL].nunique(), activation='sigmoid')(x) \n",
    "\n",
    "    # Create the full model\n",
    "    model = Model(inputs=base_model.input, outputs=x, name=\"MobilneNetV3Large_pretrained-weights_binary_fixed-layers_custom-conv2D\")\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "else:\n",
    "    # Initialize the MobileNetV3Large model\n",
    "    base_model = MobileNetV3Large(weights=None, include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "\n",
    "    # Freeze the base model's layers to use it for feature extraction\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Add custom layers on top \n",
    "    x = layers.Flatten()(base_model.output)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(train_df[TARGET_LABEL].nunique(), activation='sigmoid')(x) \n",
    "\n",
    "    # Create the full model\n",
    "    model = Model(inputs=base_model.input, outputs=x, name=\"MobilneNetV3Large_rand-weights\")\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "history = model.fit(\n",
    "    train_data_generator,\n",
    "    epochs=NUM_EPOCHS,              \n",
    "    verbose=1,                      # Adjust verbosity level\n",
    "    batch_size=None,                # Set the batch size, default is 32, can be increased to speed up training\n",
    "    callbacks=None,                 # List of callbacks to apply during training \n",
    "    validation_split=0.0,           # not needed as we use a validation data generator\n",
    "    validation_data=validation_generator,\n",
    "    shuffle=True,                   # Shuffle the training data before each epoch\n",
    "    sample_weight=None,             # Set the weights for the train data set !\n",
    "    class_weight=None,              # Set the weights for the classes, not needed if we use sample weights\n",
    "    initial_epoch=0,                # Use this to continue training from a specific epoch\n",
    "    steps_per_epoch=None,           # Set the number of steps per epoch, default is len(x_train) // batch_size\n",
    "    validation_steps=None,          # Set the number of steps for validation, default is len(x_val) // batch_size\n",
    "    validation_batch_size=None,     # Set the batch size for validation, default is batch_size\n",
    "    validation_freq=1,              # Only relevant if validation data is a generator. Set the frequency to validate the model on the validation set\n",
    "    max_queue_size=10,              # Set the max size for the generator queue\n",
    "    workers=-1,                     # Set the max number of processes to generate the data in parallel, -1 means all CPUs\n",
    "    use_multiprocessing=False       # Set to True if you use a generator in parallel, e.g. model.predict_generator()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting accuracy and loss of train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh.model_plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh.model_accuracy_on_test(model, test_df, TARGET_LABEL, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now()\n",
    "model_path = f\"../models/model_{timestamp}.h5\"\n",
    "model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
