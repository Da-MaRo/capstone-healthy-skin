{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook reloads previously saved models and prints the evaluation for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from helperfunctions import modelhelper as mh\n",
    "\n",
    "TARGET_VAR = \"dx_tertiary\"\n",
    "MODEL_PATH = \"../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test_df from file\n",
    "test_df = pd.read_csv(\"../data/processed/test_from_Metadata_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the models in MODEL_PATH\n",
    "model_list = os.listdir(MODEL_PATH)\n",
    "\n",
    "# just keep elements with -h5 extension\n",
    "model_list = [model for model in model_list if model[-3:] == \".h5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all custom objects in this dictionary\n",
    "\n",
    "custom_objects = {\n",
    "    'f1_score': mh.f1_score,\n",
    "    'focal_loss': mh.focal_loss_multiclass,\n",
    "    # add more custom objects here if needed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in model_list:\n",
    "    # load the model\n",
    "    model = tf.keras.models.load_model(MODEL_PATH + file_name, custom_objects=custom_objects)\n",
    "    print(f\"Loading file: '{file_name}'\")\n",
    "    # get the model name\n",
    "    model_name = model.name\n",
    "    print(f\"Evaluation model: '{model_name}'...\")\n",
    "    # get the image dimension from the loaded model\n",
    "    IMAGE_SIZE = model.input_shape[1:3]\n",
    "    print(f\"Image size: {IMAGE_SIZE}\")\n",
    "    # get the target variable from global variable\n",
    "    print(f\"Target variable is set to: {TARGET_VAR}\")\n",
    "    print(\"\\n\")\n",
    "    mh.model_accuracy_on_test(model, test_df, TARGET_VAR, IMAGE_SIZE)\n",
    "    \n",
    "    print(\"====\"*10)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
